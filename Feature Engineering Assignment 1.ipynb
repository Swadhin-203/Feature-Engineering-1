{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d356c84",
   "metadata": {},
   "source": [
    "# Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "Ans:In real world of data set, missing data, or missing values, occur when no data value is stored for the variable in an observation. Missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data.The cause of missing values can be data corruption or failure to record data. The handling of missing data is very important during the preprocessing of the dataset as many machine learning algorithms do not support missing values.Histogram based Gradient-boosting Classifier / Regressor are some algorithims that are not affected by missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a4bcea",
   "metadata": {},
   "source": [
    "# Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "Ans:The techniques those are used to handle missing data are\n",
    "1-Delete the rows and the data point to handle missing value\n",
    "2-Column wise deletion\n",
    "3-Mean value imputation\n",
    "4-Median value imputation\n",
    "5-Mode value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c677f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code For handleing missing value\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f75f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9500e1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8944c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "1           1       1  female  38.0      1      0  71.2833        C  First   \n",
       "3           1       1  female  35.0      1      0  53.1000        S  First   \n",
       "6           0       1    male  54.0      0      0  51.8625        S  First   \n",
       "10          1       3  female   4.0      1      1  16.7000        S  Third   \n",
       "11          1       1  female  58.0      0      0  26.5500        S  First   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...    ...   \n",
       "871         1       1  female  47.0      1      1  52.5542        S  First   \n",
       "872         0       1    male  33.0      0      0   5.0000        S  First   \n",
       "879         1       1  female  56.0      0      1  83.1583        C  First   \n",
       "887         1       1  female  19.0      0      0  30.0000        S  First   \n",
       "889         1       1    male  26.0      0      0  30.0000        C  First   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "6      man        True    E  Southampton    no   True  \n",
       "10   child       False    G  Southampton   yes  False  \n",
       "11   woman       False    C  Southampton   yes   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "871  woman       False    D  Southampton   yes  False  \n",
       "872    man        True    B  Southampton    no   True  \n",
       "879  woman       False    C    Cherbourg   yes  False  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "\n",
       "[182 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-Delete the rows and the data point to handle missing value\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01a178fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex  sibsp  parch     fare   class    who  \\\n",
       "0           0       3    male      1      0   7.2500   Third    man   \n",
       "1           1       1  female      1      0  71.2833   First  woman   \n",
       "2           1       3  female      0      0   7.9250   Third  woman   \n",
       "3           1       1  female      1      0  53.1000   First  woman   \n",
       "4           0       3    male      0      0   8.0500   Third    man   \n",
       "..        ...     ...     ...    ...    ...      ...     ...    ...   \n",
       "886         0       2    male      0      0  13.0000  Second    man   \n",
       "887         1       1  female      0      0  30.0000   First  woman   \n",
       "888         0       3  female      1      2  23.4500   Third  woman   \n",
       "889         1       1    male      0      0  30.0000   First    man   \n",
       "890         0       3    male      0      0   7.7500   Third    man   \n",
       "\n",
       "     adult_male alive  alone  \n",
       "0          True    no  False  \n",
       "1         False   yes  False  \n",
       "2         False   yes   True  \n",
       "3         False   yes  False  \n",
       "4          True    no   True  \n",
       "..          ...   ...    ...  \n",
       "886        True    no   True  \n",
       "887       False   yes   True  \n",
       "888       False    no  False  \n",
       "889        True   yes   True  \n",
       "890        True    no   True  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-Column wise deletion\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b610bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_mean</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age_mean   age\n",
       "0    22.000000  22.0\n",
       "1    38.000000  38.0\n",
       "2    26.000000  26.0\n",
       "3    35.000000  35.0\n",
       "4    35.000000  35.0\n",
       "..         ...   ...\n",
       "886  27.000000  27.0\n",
       "887  19.000000  19.0\n",
       "888  29.699118   NaN\n",
       "889  26.000000  26.0\n",
       "890  32.000000  32.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-Mean value imputation\n",
    "df[\"Age_mean\"]=df[\"age\"].fillna(df[\"age\"].mean())\n",
    "df[[\"Age_mean\",\"age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0bec24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch  fare embarked  class  \\\n",
       "61          1       1  female  38.0      0      0  80.0      NaN  First   \n",
       "829         1       1  female  62.0      0      0  80.0      NaN  First   \n",
       "\n",
       "       who  adult_male deck embark_town alive  alone  \n",
       "61   woman       False    B         NaN   yes   True  \n",
       "829  woman       False    B         NaN   yes   True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4-Median value imputation\n",
    "df[df[\"embarked\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26909810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embarked\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f412330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value=df[df[\"embarked\"].notna()][\"embarked\"].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c24fb909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Embraked_mode\"]=df[\"embarked\"].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0d899f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embraked_mode</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embraked_mode embarked\n",
       "0               S        S\n",
       "1               C        C\n",
       "2               S        S\n",
       "3               S        S\n",
       "4               S        S\n",
       "..            ...      ...\n",
       "886             S        S\n",
       "887             S        S\n",
       "888             S        S\n",
       "889             C        C\n",
       "890             Q        Q\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Embraked_mode\",\"embarked\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874c8c8",
   "metadata": {},
   "source": [
    "# Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "Ans:A classification data set with skewed class porpotions is called imbalanced data set. Classes that covers the large proportions of the data set are called as the majority classes. The classes that covers the less proportions of the data set is called as the minority classes.Imbalanced dat set will lead algorithims to get good results by returning the majority.That will be a problem if we are interested in  the minority more.So, balancing is a way to force the algorithim to give more weight to the minority.If imbalanced datasets are not handled, the resulting model may be biased towards the majority class and unable to accurately predict the minority class. This can result in incorrect predictions and misclassification of minority class instances, which may have serious consequences in applications such as fraud detection, medical diagnosis, and anomaly detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b663025d",
   "metadata": {},
   "source": [
    "# Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required?\n",
    "Ans:Up-sampling and Down-sampling are two common used to handle imbalanced datasets in machine learning.\n",
    "### Up-sampling:-\n",
    "Up-sampling involves increasing the number of instances in the minority class to balance the class distribution. This can be done by randomly duplicating instances from the minority class, or by generating new synthetic instances. The goal of up-sampling is to increase the representation of the minority class in the dataset, and to give the model more exposure to the minority class during training.\n",
    "\n",
    "Example:-An example where up-sampling may be required is in credit card fraud detection. In this case, the number of fraudulent transactions is typically much smaller than the number of legitimate transactions. Therefore, the dataset is imbalanced, and the minority class (fraudulent transactions) is underrepresented.\n",
    "\n",
    "### Down-sampling:-\n",
    "Down-sampling involves reducing the number of instances in the majority class to balance the class distribution. This can be done by randomly removing instances from the majority class. The goal of down-sampling is to reduce the bias towards the majority class and to give the model a more balanced representation of the classes during training.\n",
    "Example:-An example where down-sampling may be required is in email spam detection. In this case, the number of spam emails is typically much larger than the number of legitimate emails. Therefore, the dataset is imbalanced, and the majority class (spam emails) is overrepresented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65945f2b",
   "metadata": {},
   "source": [
    "# Q5: What is data Augmentation? Explain SMOTE.\n",
    "Ans:Data augmentation is a technique used to increase the size of a dataset by artificially creating new examples that are similar to the original data. This technique is often used in machine learning to address issues with limited data, such as overfitting or imbalanced datasets.\n",
    "\n",
    "There are several ways to perform data augmentation, including image rotation, flipping, cropping, and changing the brightness and contrast of an image. In the context of text data, augmentation can involve techniques such as adding synonyms, replacing words with their antonyms, or swapping words in a sentence.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a specific data augmentation technique that is commonly used to address imbalanced datasets. SMOTE creates synthetic samples of the minority class by interpolating new examples between existing minority class instances.\n",
    "\n",
    "Here is how SMOTE works:\n",
    "\n",
    "1-Select a minority class instance at random\n",
    "2-Identify its k nearest neighbors (k is a hyperparameter)\n",
    "3-Choose one of the k nearest neighbors at random\n",
    "4-Generate a new instance by interpolating between the selected instance and the chosen neighbor\n",
    "5-Repeat steps 1-4 until the desired number of new minority class instances is generated.\n",
    "\n",
    "SMOTE helps to address the class imbalance problem by creating new examples of the minority class, which can improve the ability of machine learning models to generalize to the minority class. SMOTE can be used in conjunction with other techniques such as random undersampling, which involves randomly removing instances from the majority class to balance the class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9577bf3",
   "metadata": {},
   "source": [
    "# Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "Ans:Outliers are data points that are significantly different from other data points in a dataset. Outliers can be caused by various factors such as measurement errors, data entry errors, or extreme values that represent rare events.\n",
    "\n",
    "It is essential to handle outliers in a dataset because they can have a significant impact on statistical measures and machine learning models. Outliers can affect the mean and standard deviation, which are commonly used statistical measures to describe a dataset. If the dataset contains outliers, the mean may be skewed towards the outlier values, which can lead to incorrect interpretations of the data.\n",
    "\n",
    "In machine learning, outliers can have a significant impact on the performance of models. Outliers can affect the fitting of the model, leading to overfitting or underfitting. Overfitting occurs when the model is too complex and captures noise in the data, including outliers. Underfitting occurs when the model is too simple and is unable to capture the underlying patterns in the data.\n",
    "\n",
    "Handling outliers is essential to ensure that machine learning models are accurate and reliable. There are several techniques that can be used to handle outliers, including:\n",
    "\n",
    "Removing outliers: One approach is to remove outliers from the dataset. However, this approach should be used with caution as it can lead to the loss of valuable information and potential bias in the remaining data.\n",
    "\n",
    "Transforming the data: Transforming the data can help to reduce the impact of outliers. For example, using logarithmic or square root transformations can help to reduce the influence of extreme values.\n",
    "\n",
    "Using robust statistical measures: Using robust statistical measures such as median and interquartile range (IQR) can help to reduce the impact of outliers on statistical measures.\n",
    "\n",
    "Using outlier detection algorithms: Outlier detection algorithms can be used to identify and remove outliers from the dataset. These algorithms include methods such as Z-score, boxplots, and local outlier factor (LOF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2ce7d",
   "metadata": {},
   "source": [
    "# Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "Ans:Handling missing data is an important part of data analysis. There are several techniques that I can be used to handle missing data, including:\n",
    "\n",
    "1-Deleting missing data: One approach is to delete rows or columns that contain missing data. This method is simple and straightforward, but it can result in a loss of valuable information.\n",
    "\n",
    "2-Imputing missing data: Imputing missing data involves replacing missing values with estimated values. There are several methods for imputing missing data, including mean imputation, median imputation, mode imputation, regression imputation, and k-nearest neighbor (KNN) imputation. Each method has its strengths and weaknesses, and the choice of method will depend on the specific characteristics of the dataset.\n",
    "\n",
    "3-Using models that can handle missing data: Some machine learning algorithms, such as decision trees, can handle missing data by splitting nodes based on the available data rather than using all the data to make a decision. Other algorithms, such as KNN, can also handle missing data by using the available data to estimate the missing values.\n",
    "\n",
    "4-Using data augmentation techniques: Data augmentation techniques, such as SMOTE, can be used to generate synthetic data to replace missing values.\n",
    "\n",
    "5-Conducting sensitivity analysis: Sensitivity analysis involves examining the effect of different assumptions about the missing data on the results of the analysis. This approach can help to identify the impact of missing data on the analysis and provide insight into the robustness of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c0973",
   "metadata": {},
   "source": [
    "# Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
    "Ans:When working with a large dataset, it is important to understand whether the missing data is missing at random (MAR), missing completely at random (MCAR), or missing not at random (MNAR). MAR refers to missing data where the probability of a value being missing depends only on observed data. MCAR refers to missing data where the probability of a value being missing does not depend on either observed or unobserved data. MNAR refers to missing data where the probability of a value being missing depends on unobserved data.\n",
    "\n",
    "There are several strategies that can be used to determine if the missing data is missing at random or if there is a pattern to the missing data:\n",
    "\n",
    "1-Visual inspection: One approach is to visually inspect the data to see if there is a pattern to the missing data. For example, if the missing data occurs more frequently in certain rows or columns, this may suggest that there is a pattern to the missing data.\n",
    "\n",
    "2-Statistical tests: Statistical tests, such as chi-squared tests, can be used to test whether the missing data is MCAR. If the test is significant, this suggests that the missing data is not MCAR and there is a pattern to the missing data.\n",
    "\n",
    "3-Imputation methods: Different imputation methods can be used to impute the missing data, and the results can be compared to see if there is a pattern to the missing data. For example, if different imputation methods produce similar results, this suggests that the missing data is MAR.\n",
    "\n",
    "4-Machine learning models: Machine learning models can be used to predict the missing values based on the observed data. If the accuracy of the model is high, this suggests that the missing data is MAR.\n",
    "\n",
    "5-Domain knowledge: Expert knowledge about the dataset can be used to determine if there is a pattern to the missing data. For example, if the missing data occurs more frequently in certain categories, this may suggest that there is a pattern to the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78edcc",
   "metadata": {},
   "source": [
    "# Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you  can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "Ans:When working with imbalanced datasets, where one class is much more prevalent than the other, it can be challenging to evaluate the performance of machine learning models. In the case of a medical diagnosis project where the majority of patients do not have the condition of interest, some strategies to evaluate the performance of the machine learning model are:\n",
    "\n",
    "1-Use evaluation metrics that are robust to imbalanced datasets: Accuracy may not be the best metric to evaluate the performance of the model since it does not take into account the imbalanced nature of the dataset. Instead, evaluation metrics such as precision, recall, F1 score, and Area Under the ROC Curve (AUC-ROC) are more appropriate for imbalanced datasets.\n",
    "\n",
    "2-Resampling techniques: Resampling techniques such as oversampling the minority class or undersampling the majority class can be used to balance the dataset. This can improve the performance of the machine learning model by providing more balanced training data.\n",
    "\n",
    "3-Cost-sensitive learning: Cost-sensitive learning involves assigning different misclassification costs to different classes. This can help the machine learning model to prioritize the minority class and reduce the impact of the imbalanced nature of the dataset.\n",
    "\n",
    "4-Ensemble methods: Ensemble methods such as bagging, boosting, or stacking can be used to combine multiple machine learning models and improve the overall performance. This is particularly useful for imbalanced datasets since it can help to address the class imbalance problem.\n",
    "\n",
    "5-Threshold tuning: The threshold for classification can be adjusted to prioritize recall over precision or vice versa, depending on the specific requirements of the application. This can help to improve the performance of the model on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d413bc6f",
   "metadata": {},
   "source": [
    "# Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n",
    "Ans:When dealing with an unbalanced dataset in which the majority class overwhelms the minority class, it is essential to balance the dataset before training a machine learning model. One possible approach is to down-sample the majority class, which involves randomly selecting a subset of the majority class instances such that the resulting dataset has a balanced class distribution. Here are some methods that can be employed to balance the dataset and down-sample the majority class:\n",
    "\n",
    "1-Random under-sampling: Randomly remove instances from the majority class until the dataset is balanced. This method can be useful when the majority class has many instances and the minority class is small.\n",
    "\n",
    "2-Cluster-based under-sampling: Use clustering techniques to identify groups of instances in the majority class that are similar to each other and select only one instance from each group to include in the final dataset.\n",
    "\n",
    "3-Tomek Links: Identify pairs of instances that are closest to each other, but belong to different classes. In this case, instances from the majority class can be removed to balance the dataset.\n",
    "\n",
    "4-NearMiss: This algorithm removes instances from the majority class that are closest to the instances in the minority class. There are three variants of the algorithm based on the distance metric used to define closeness.\n",
    "\n",
    "5-Edited Nearest Neighbors (ENN): This algorithm uses k-nearest neighbors to identify instances that are misclassified, and it removes them from the dataset.\n",
    "\n",
    "6-Synthetic Minority Over-sampling Technique (SMOTE): This method is not a down-sampling technique but can be used to balance the dataset by oversampling the minority class. SMOTE generates synthetic examples of the minority class by interpolating between existing minority class examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef1e425",
   "metadata": {},
   "source": [
    "# Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?\n",
    "Ans:\n",
    "When dealing with a dataset that is unbalanced with a low percentage of occurrences of a rare event, it is important to balance the dataset before training a machine learning model. One possible approach is to up-sample the minority class, which involves generating additional instances of the minority class to increase its representation in the dataset. Here are some methods that can be employed to balance the dataset and up-sample the minority class:\n",
    "\n",
    "Random over-sampling: Randomly replicate instances of the minority class until the dataset is balanced. This method can be useful when the minority class has very few instances.\n",
    "\n",
    "Synthetic Minority Over-sampling Technique (SMOTE): SMOTE generates synthetic examples of the minority class by interpolating between existing minority class examples. This method can be used to balance the dataset by oversampling the minority class.\n",
    "\n",
    "Adaptive Synthetic Sampling (ADASYN): This algorithm is an extension of SMOTE that generates more synthetic examples for the minority class instances that are harder to learn based on the number of examples around them.\n",
    "\n",
    "SMOTEBoost: This algorithm combines SMOTE and boosting, a technique that iteratively trains weak models and focuses on the misclassified instances, to create synthetic instances of the minority class and balance the dataset.\n",
    "\n",
    "Weighting the classes: Assigning weights to the classes in the training algorithm can also be an effective way to balance the dataset. This method involves assigning higher weights to the minority class instances and lower weights to the majority class instances during the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c635c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9e1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3117b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e94188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
